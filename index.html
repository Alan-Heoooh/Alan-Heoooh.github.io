<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Zihao He | 何子浩</title>
    <meta name="author" content="Zihao He">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.jpg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Zihao He 何子浩
                    </p>
                    <p>
                      I am a senior undergraduate student at <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, majoring in Electrical and Computer Engineering. I am currently a visiting research intern at <a href="https://ucsd.edu/">UCSD</a>, advised by <a href="https://cseweb.ucsd.edu/~haosu/">Prof. Hao Su</a>. Previously, I was a member of <a href="https://www.mvig.org/"> SJTU Machine Vision and Intelligence Group (MVIG)</a>, advised by <a href="https://fang-haoshu.github.io/">Dr. Hao-Shu Fang</a>, and <a href="https://www.mvig.org/">Prof. Cewu Lu</a>.
                      <br></br>
                      My research interests mainly lie in <b>dexterous manipulation</b>, <b>tactile sensing</b>, and <b>cross-embodiment learning</b> with the ultimate goal of building intelligent robots with <i>human-level manipulation dexterity</i>.
                    </p>
                    <p style="text-align:center">
                      <a href="mailto:alanheoooh@gmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=fzKelVAAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                      <a href="https://x.com/zihao_alan">X</a> &nbsp;/&nbsp;
                      <a href="https://github.com/Alan-Heoooh">Github</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:37%;max-width:37%">
                    <a href="images/Zihao-2.png">
                      <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Zihao-2.png" class="hoverZoomLink">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>News</h2>
                    <p>
                      <b>[Aug. 2025]</b> <a href="https://airexo.tech/airexo2">AirExo-2</a> is accepted by CoRL 2025.<br>
                      <b>[Jun. 2025]</b> <a href="https://tonyfang.net/FoAR">FoAR</a> is accepted by IROS 2025. See you in Hangzhou! <br>
                      <b>[Apr. 2025]</b> <a href="https://tonyfang.net/FoAR">FoAR</a> is accepted by RA-L. <br>
                      <b>[Mar. 2025]</b> <a href="https://airexo.tech/airexo2">AirExo-2</a> is released! Check our website for more details.<br>
                      <b>[Nov. 2024]</b> <a href="https://tonyfang.net/FoAR">FoAR</a> is released! Check our website for more details.<br>
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:100%;vertical-align:middle">
                    <h2>Research</h2>
                    <p>
                      Representative papers are <span class="highlight">highlighted</span>. * denotes equal contribution. † denotes corresponding author(s).
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <video src='images/research/dqrise.mp4' width="160" autoplay muted playsinline loop></div>
                  </td>
      
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle><a href="http://rise-policy.github.io/DQ-RISE">Learning Dexterous Manipulation with Quantized Hand State</a> </papertitle>
                    <br>
                    <a href="mailto:fyyy0407@sjtu.edu.cn">Ying Feng*</a>,
                    <a href="https://tonyfang.net/">Hongjie Fang*</a>,
                    <a href="https://hyn-kulu.github.io/">Yinong He*</a>,
                    <a href="mailto:jjchen20@sjtu.edu.cn">Jingjing Chen</a>,
                    <a href="https://scholar.google.com/citations?user=bK1fWXcAAAAJ">Chenxi Wang</a>,
                    <strong>Zihao He</strong>, 
                    <a href="https://ruonanliu.com/">Ruonan Liu</a>,
                    <a href="https://www.mvig.org/">Cewu Lu†</a>
                    <br>
                    <em>arXiv</em>, 2025 
                    <br>
                    <a href="https://arxiv.org/pdf/2509.17450">paper</a> / <a href="">code comming soon</a> / <a href="http://rise-policy.github.io/DQ-RISE">project page</a>
                    <p></p>
                    <p>
                      Propose DQ-RISE, which quantizes hand states to simplify hand motion prediction while preserving essential patterns, and applies a continuous relaxation that allows arm actions to diffuse jointly with these compact hand states. This design enables the policy to learn arm-hand coordination from data while preventing hand actions from overwhelming the action space. Experiments show that DQ-RISE achieves more balanced and efficient learning, paving the way toward structured and generalizable dexterous manipulation.
                    </p>
                  </td>
                </tr> 

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/research/airexo2.gif' width="160">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                      <strong><a href="https://airexo.tech/airexo2">AirExo-2: Scaling up Generalizable Robotic Imitation Learning with Low-Cost Exoskeletons</a></strong>
                    </papertitle>
                    <br>
                    <a href="https://tonyfang.net/">Hongjie Fang*</a>,
                    <a href="https://scholar.google.com/citations?user=bK1fWXcAAAAJ">Chenxi Wang*</a>,
                    <a href="mailto:sommerfeld@sjtu.edu.cn">Yiming Wang*</a>,
                    <a href="mailto:jjchen20@sjtu.edu.cn">Jingjing Chen*</a>,
                    <a href="https://github.com/Xiashangning">Shangning Xia</a>,
                    <a href="https://lyuj1998.github.io/">Jun Lv</a>,
                    <strong>Zihao He</strong>,
                    <a href="mailto:simonyxy@sjtu.edu.cn">Xiyan Yi</a>,
                    <a href="mailto:yunhan_guo@sjtu.edu.cn">Yunhan Guo</a>,
                    <a href="https://github.com/kelvin34501">Xinyu Zhan</a>,
                    <a href="https://lixiny.github.io/">Lixin Yang</a>,
                    <a href="mailto:wangweiming@sjtu.edu.cn">Weiming Wang</a>,
                    <a href="https://www.mvig.org/">Cewu Lu†</a>,
                    <a href="https://fang-haoshu.github.io/">Hao-Shu Fang†</a>
                    <br>
                    <em>CoRL</em>, 2025 <b><text style="color:red">(oral)</text></b> &nbsp 
                    <br>
                    <a href="https://arxiv.org/abs/2503.03081">paper</a> / <a href="https://github.com/AirExo/AirExo-2">data collection code</a> / <a href="https://github.com/rise-policy/RISE-2/">policy code</a> / <a href="https://airexo.tech/airexo2">project page</a>
                    <p></p>
                    <p>
                      Develop <i>AirExo</i>-2, an updated low-cost exoskeleton system for large-scale in-the-wild demonstration collection. By transforming the collected in-the-wild demonstrations into pseudo-robot demonstrations, our system addresses key challenges in utilizing in-the-wild demonstrations for downstream imitation learning in the real world. Propose <i>RISE</i>-2, a generalizable imitation policy that integrates 2D and 3D perceptions, outperforming previous imitation learning policies in both in-domain and out-of-domain tasks, even with limited demonstrations. By leveraging in-the-wild demonstrations collected and transformed by the <i>AirExo</i>-2 system, without the need for additional robot demonstrations, <i>RISE</i>-2 achieves comparable or superior performance to policies trained with teleoperated data, highlighting the potential of <i>AirExo</i>-2 for scalable and generalizable imitation learning.
                    </p>
                  </td>
                </tr>

                <tr bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/research/foar.gif' width="160">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                      <strong><a href="https://tonyfang.net/FoAR/">FoAR: Force-Aware Reactive Policy for Contact-Rich Robotic Manipulation</a></strong>
                    </papertitle>
                    <br>
                    <strong>Zihao He*</strong>,
                    <a href="https://tonyfang.net/">Hongjie Fang*</a>,
                    <a href="mailto:jjchen20@sjtu.edu.cn">Jingjing Chen</a>,
                    <a href="https://fang-haoshu.github.io/">Hao-Shu Fang†</a>,
                    <a href="https://www.mvig.org/">Cewu Lu†</a>
                    <br>
                    <em>RA-L</em>, 2025 &nbsp
                    <br>
                    <em>IROS</em>, 2025 &nbsp
                    <br>
                    <a href="https://arxiv.org/pdf/2411.15753">paper</a> / <a href="https://github.com/Alan-Heoooh/FoAR">code</a> / <a href="https://tonyfang.net/FoAR/">project page</a> / <a href="https://x.com/FangGalaxies/status/1861214958517936146">X</a>
                    <p></p>
                    <p>
                      Propose FoAR, a force-aware reactive policy that combines high-frequency force/torque sensing with visual inputs to enhance the performance in contact-rich manipulation. Built upon the RISE policy, FoAR incorporates a multimodal feature fusion mechanism guided by a future contact predictor, enabling dynamic adjustment of force/torque data usage between non-contact and contact phases. Its reactive control strategy also allows FoAR to accomplish contact-rich tasks accurately through simple position control.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding-bottom: 0;"> <!-- 减少底部的padding -->
                    <h2 style="margin-bottom: 0px;">Selected Awards and Honors</h2> <!-- 减少margin-bottom -->
                  </td>
                </tr>
                <tr>
                  <td>
                    <ul>
                      <li>2025: The Sam and Daisy Wu Scholarship (10 winners in JI)</li>
                      <li>2025: Student Development Scholarship - Sports (5 winners in JI) </li>
                      <li>2024: John Wu & Jane Sun Excellence Scholarship (10 winners in JI)</li>
                      <li>2024: Student Development Scholarship - Sports (5 winners in JI) </li>
                      <li>2024: Fan Hsu-chi Scholarship (15 winners in SJTU)</li>
                      <li>2023: <strong>National Scholarship (Top 0.2% nationwide)</strong></li>
                      <li>2023: John Wu & Jane Sun Excellence Scholarship (10 winners in JI)</li>
                      <li>2023: A-level Merit Scholarship (Top 1% SJTU)</li>
                      <li>2023: Merit Student (Top 5% SJTU)</li>
                      <li>2022: Silver Medal Winner of University Physics Competition</li>
                      <li>2021: First Prize in Chinese Physics Olympiad (CPhO), Zhejiang Province</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:0px">
                    <br>
                    <p style="text-align:right;font-size:small;">
                      The website is built upon this <a href="https://github.com/jonbarron/jonbarron_website">template</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
