<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Scaling Cross-Embodiment World Models for Dexterous Manipulation</title>
  
  <!-- SEO Meta Tags -->
  <meta name="description" content="We develop a particle-based cross-embodiment world model for dexterous manipulation that transfers zero-shot to diverse real robot hands.">
  <meta name="keywords" content="dexterous manipulation, world models, cross-embodiment learning, robotics, graph neural networks">
  <meta name="author" content="Zihao He, Bo Ai, Tongzhou Mu, Yulin Liu, Weikang Wan, Jiawei Fu, Yilun Du, Henrik I. Christensen, Hao Su">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://alan-heoooh.github.io/dexwm.html">
  <meta property="og:title" content="Scaling Cross-Embodiment World Models for Dexterous Manipulation">
  <meta property="og:description" content="We develop a particle-based cross-embodiment world model for dexterous manipulation that transfers zero-shot to diverse real robot hands.">
  <meta property="og:image" content="https://alan-heoooh.github.io/images/research/DexWM.mp4">
  
  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://alan-heoooh.github.io/dexwm.html">
  <meta property="twitter:title" content="Scaling Cross-Embodiment World Models for Dexterous Manipulation">
  <meta property="twitter:description" content="We develop a particle-based cross-embodiment world model for dexterous manipulation that transfers zero-shot to diverse real robot hands.">
  <meta property="twitter:image" content="https://alan-heoooh.github.io/images/research/DexWM.mp4">
  
  <!-- Favicon -->
  <link rel="shortcut icon" href="images/favicon/favicon.jpg" type="image/x-icon">
  
  <!-- Styles -->
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      line-height: 1.6;
      color: #333;
      background-color: #fff;
    }
    
    p {
      font-size: 18px;
    }
    
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 20px;
    }
    
    .header {
      text-align: center;
      padding: 40px 20px 20px;
      border-bottom: 1px solid #e0e0e0;
      margin-bottom: 40px;
    }
    
    .header h1 {
      font-size: 32px;
      font-weight: 700;
      margin: 0 0 20px;
      color: #1a1a1a;
    }
    
    .authors {
      font-size: 18px;
      margin: 15px 0;
      line-height: 1.8;
    }
    
    .authors a {
      color: #1772d0;
      text-decoration: none;
      font-size: 18px;
    }
    
    .authors a:hover {
      color: #f09228;
    }
    
    .affiliation {
      font-size: 16px;
      color: #666;
      margin: 10px 0;
    }
    
    .authors sup {
      font-size: 0.7em;
      vertical-align: super;
    }
    
    .affiliations {
      font-size: 16px;
      color: #666;
      margin: 15px 0;
      line-height: 1.8;
      text-align: center;
    }
    
    .affiliations sup {
      font-size: 0.7em;
      vertical-align: super;
    }
    
    .links {
      margin: 20px 0;
      font-size: 16px;
    }
    
    .links a {
      color: #1772d0;
      text-decoration: none;
      margin: 0 10px;
      padding: 8px 16px;
      border: 1px solid #1772d0;
      border-radius: 4px;
      display: inline-block;
      transition: all 0.3s;
    }
    
    .links a:hover {
      background-color: #1772d0;
      color: #fff;
    }
    
    section {
      margin: 50px 0;
      padding: 20px 0;
    }
    
    section h2 {
      font-size: 24px;
      font-weight: 700;
      margin: 0 0 20px;
      color: #1a1a1a;
      border-bottom: 2px solid #1772d0;
      padding-bottom: 10px;
    }
    
    section h3 {
      font-size: 22px;
      font-weight: 700;
      margin: 30px 0 15px;
      color: #1a1a1a;
    }
    
    section h4 {
      font-size: 18px;
      font-weight: 600;
      margin: 25px 0 15px;
      color: #1a1a1a;
    }
    
    .video-container {
      text-align: center;
      margin: 30px 0;
      background-color: #f5f5f5;
      padding: 20px;
      border-radius: 8px;
    }
    
    .video-container video {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .image-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
      margin: 30px 0;
    }
    
    .image-grid img {
      width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
      gap: 20px;
      margin: 30px 0;
    }
    
    .video-item {
      background-color: #f5f5f5;
      padding: 15px;
      border-radius: 8px;
      text-align: center;
    }
    
    .video-item video {
      width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .video-item p {
      margin: 10px 0 0;
      font-size: 14px;
      color: #666;
    }
    
    .figure-container {
      text-align: center;
      margin: 30px 0;
      background-color: #f5f5f5;
      padding: 20px;
      border-radius: 8px;
    }
    
    .figure-container img {
      width: 100%;
      max-width: 900px;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .figure-container a {
      display: inline-block;
      margin-top: 10px;
      color: #1772d0;
      text-decoration: none;
    }
    
    .figure-container a:hover {
      color: #f09228;
    }
    
    .pdf-container a {
      display: inline-block;
      margin-top: 10px;
      color: #1772d0;
      text-decoration: none;
    }
    
    .pdf-container a:hover {
      color: #f09228;
    }
    
    .citation-box {
      background-color: #f5f5f5;
      padding: 20px;
      border-radius: 8px;
      border-left: 4px solid #1772d0;
      margin: 20px 0;
      position: relative;
    }
    
    .citation-box pre {
      margin: 0;
      font-family: 'Courier New', monospace;
      font-size: 13px;
      line-height: 1.5;
      white-space: pre-wrap;
      word-wrap: break-word;
    }
    
    .copy-button {
      position: absolute;
      top: 10px;
      right: 10px;
      background-color: #1772d0;
      color: white;
      border: none;
      padding: 6px 12px;
      border-radius: 4px;
      cursor: pointer;
      font-size: 12px;
      transition: background-color 0.3s;
    }
    
    .copy-button:hover {
      background-color: #f09228;
    }
    
    .copy-button.copied {
      background-color: #28a745;
    }
    
    ul {
      padding-left: 20px;
    }
    
    ul li {
      margin: 10px 0;
      font-size: 18px;
    }
    
    ul li strong {
      font-size: 18px;
    }
    
    strong {
      font-size: 18px;
    }
    
    .highlight-box {
      background-color: #ffffd0;
      padding: 20px;
      border-radius: 8px;
      margin: 20px 0;
    }
    
    .back-link {
      text-align: center;
      margin: 40px 0;
      padding: 20px;
    }
    
    .back-link a {
      color: #1772d0;
      text-decoration: none;
      font-size: 16px;
    }
    
    .back-link a:hover {
      color: #f09228;
    }
    
    @media (max-width: 768px) {
      .header h1 {
        font-size: 24px;
      }
      
      .authors {
        font-size: 14px;
      }
      
      .links a {
        display: block;
        margin: 10px 0;
      }
      
      .image-grid {
        grid-template-columns: 1fr;
      }
      
      .video-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>

<body>
  <div class="container">
    <!-- Header -->
    <div class="header">
      <h1>Scaling Cross-Embodiment World Models for Dexterous Manipulation</h1>
      <div class="authors">
        <a href="https://alan-heoooh.github.io/">Zihao He<sup>1,3</sup>*</a>,
        <a href="https://albertboai.com/">Bo Ai<sup>1</sup>*</a>,
        <a href="https://cseweb.ucsd.edu/~t3mu/">Tongzhou Mu<sup>1</sup></a>,
        <a href="https://liuyulinn.github.io/">Yulin Liu<sup>1</sup></a>,
        <a href="https://wkwan7.github.io/">Weikang Wan<sup>1</sup></a>,
        <a href="https://github.com/JayeFu">Jiawei Fu<sup>1</sup></a>,
        <br>
        <a href="https://yilundu.github.io/">Yilun Du<sup>2</sup></a>,
        <a href="https://hichristensen.com/">Henrik I. Christensen<sup>1</sup>‚Ä†</a>,
        <a href="https://cseweb.ucsd.edu/~haosu/index.html">Hao Su<sup>1,4</sup>‚Ä†</a>
      </div>
      <div style="text-align: center; margin: 10px 0; font-size: 16px; color: #666;">
        *Equal contribution &nbsp;&nbsp; ‚Ä†Equal advising
      </div>
      <div class="affiliations">
        <sup>1</sup>UC San Diego &nbsp;&nbsp;
        <sup>2</sup>Harvard University &nbsp;&nbsp;
        <sup>3</sup>Shanghai Jiao Tong University &nbsp;&nbsp;
        <sup>4</sup>Hillbot
      </div>
      <div class="affiliation">
        <em>arXiv</em>, 2025
      </div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2511.01177" target="_blank">üìÑ Paper</a>
        <!-- <a href="https://github.com/[your-repo]" target="_blank">üíª Code</a>
        <a href="index.html">üè† Home</a> -->
      </div>
    </div>

    <!-- Teaser Video -->
    <section id="teaser">
      <div class="video-container">
        <video src="static/dexwm/videos/teaser.mp4" controls autoplay muted playsinline loop poster="">
          Your browser does not support the video tag.
        </video>
      </div>
    </section>

    <!-- Abstract -->
    <section id="abstract">
      <h2>Abstract</h2>
      <p>
        Cross-embodiment learning seeks to build generalist robots that operate across diverse morphologies, but differences in action spaces and kinematics hinder data sharing and policy transfer. This raises a central question: Is there any invariance that allows actions to transfer across embodiments? We conjecture that environment dynamics are embodiment-invariant, and that world models capturing these dynamics can provide a unified interface across embodiments. To learn such a unified world model, the crucial step is to design state and action representations that abstract away embodiment-specific details while preserving control relevance. To this end, we represent different embodiments (e.g., human hands and robot hands) as sets of 3D particles and define actions as particle displacements, creating a shared representation for heterogeneous data and control problems. A graph-based world model is then trained on exploration data from diverse simulated robot hands and real human hands, and integrated with model-based planning for deployment on novel hardware. Experiments on rigid and deformable manipulation tasks reveal three findings: (i) scaling to more training embodiments improves generalization to unseen ones, (ii) co-training on both simulated and real data outperforms training on either alone, and (iii) the learned models enable effective control on robots with varied degrees of freedom. These results establish world models as a promising interface for cross-embodiment dexterous manipulation.
      </p>
    </section>

    <!-- Method -->
    <section id="method">
      <h2>Method</h2>
      
      <!-- Method Figure -->
      <div class="figure-container">
        <img src="static/dexwm/images/fig1-method.jpg" alt="Method overview: Cross-Embodiment World Model Learning and Model-Predictive Control">
        <br>
        <a href="static/dexwm/images/fig1-method.jpg" target="_blank">View full-size image</a>
      </div>
      
      <p>
        Our approach addresses the challenge of transferring manipulation skills across different robotic embodiments by introducing a unified particle-based representation. Key components include:
      </p>
      <ul>
        <li><strong>Particle Representation:</strong> Both robot hands, human hands, and objects are represented as sets of 3D particles, creating a shared state and action space across embodiments.</li>
        <li><strong>Action Encoding:</strong> Actions are expressed as particle displacement fields, enabling a consistent action representation regardless of the specific embodiment's degrees of freedom.</li>
        <li><strong>World Model:</strong> A particle-based graph neural network (DPI-Net) serves as the world model, leveraging graph structure to model interactions between particles and incorporating strong inductive biases for manipulation tasks.</li>
        <li><strong>Zero-Shot Transfer:</strong> The learned world model generalizes to diverse real robot hands with different kinematic structures without additional training.</li>
      </ul>
    </section>

    <!-- Results -->
    <section id="results">
      <h2>Results</h2>
      
      <h3>Evaluating Cross-embodiment World Model Learning</h3>
      <p>
        We systematically evaluate how the number of training embodiments influences generalization to unseen embodiments. For each target hand, we hold it out and train on <em>x</em> other hands, enumerating all <em>C(N,x)</em> subsets from <em>N=6</em> total hands. In addition, the case <em>x=6</em> corresponds to training on all hands, including the target, and provides a reference for the upper bound of cross-embodiment learning in the current data regime.
      </p>
      
      <div class="figure-container">
        <img src="static/dexwm/images/fig3-scaling.jpg" alt="Scaling analysis: MSE Loss vs Number of Training Embodiments for Object Pushing and Plasticine Reshaping tasks">
        <br>
        <a href="static/dexwm/images/fig3-scaling.jpg" target="_blank">View full-size image</a>
      </div>
      
      <h4>Key Observations</h4>
      <ul>
        <li><strong>Embodiment scaling law:</strong> More training embodiments -> better generalization. </li>
        <li><strong>Zero-shot strength at <em>x=5</em>:</strong> Performance can surpass direct training on the target embodiment <b>without ever seeing it</b>.        </li>
        <li><strong>Benefit of co-training at <em>x=6*</em>:</strong> Training on all embodiments <b>outperforms</b> direct training on the target embodiment. </li>
      </ul>
      
      <h3>Co-Training Recipe</h3>
      <p>
        We co-train a single world model on mixed simulated robot interactions and real human demonstrations, and sweep the amount of simulation data relative to a fixed human dataset. Evaluated on held-out human interactions (CD/EMD error), simulation-only performs worst, human-only is a strong baseline, and a balanced ~1:1 sim-to-human mix yields the best accuracy‚Äîsuggesting simulation acts as a regularizer rather than a replacement for real data. 
      </p>
      
      <div class="figure-container">
        <img src="static/dexwm/images/recipe.jpg" alt="Co-Training Recipe: CD+EMD Error comparison for Object Pushing and Plasticine Reshaping tasks with different simulation-to-real data ratios" style="max-width: 700px;">
        <br>
        <a href="static/dexwm/images/recipe.jpg" target="_blank">View full-size image</a>
      </div>
    
      
      <h3>Evaluating Model-Based Control</h3>
      <p>
        We evaluate the learned cross-embodiment world models for model-based control on real robot hardware. The following videos demonstrate the zero-shot transfer capabilities of our approach across different robotic embodiments (Ability Hand and XHand) with different kinematic structure and action spaces. 
        <br>
        All videos are played at 5√ó speed.
      </p>
      
      <h4>Ability Hand (6-DoF) Results</h4>
      <div class="video-grid">
        <div class="video-item">
          <video src="static/dexwm/videos/ability_hand_reshaping_X_compressed.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>Ability Hand Reshaping: Letter X</p>
        </div>
        <div class="video-item">
          <video src="static/dexwm/videos/ability_hand_reshaping_R_5x.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>Ability Hand Reshaping: Letter R</p>
        </div>
      </div>
      
      <h4>XHand (12-DoF) Results</h4>
      <div class="video-grid">
        <div class="video-item">
          <video src="static/dexwm/videos/xhand_reshaping_X_compressed.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>XHand Reshaping: Letter X</p>
        </div>
        <div class="video-item">
          <video src="static/dexwm/videos/xhand_reshaping_R_5x.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>XHand Reshaping: Letter R</p>
        </div>
      </div>
      
      <div class="video-grid">
        <div class="video-item">
          <video src="static/dexwm/videos/xhand_reshaping_T_compressed.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>XHand Reshaping: Letter T</p>
        </div>
        <div class="video-item">
          <video src="static/dexwm/videos/xhand_reshaping_A_compressed.mp4" controls muted playsinline>
            Your browser does not support the video tag.
          </video>
          <p>XHand Reshaping: Letter A</p>
        </div>
      </div>
    </section>

    <!-- Citation -->
    <section id="citation">
      <h2>Citation</h2>
      <div class="citation-box">
        <button class="copy-button" onclick="copyCitation()">Copy</button>
        <pre id="bibtex">@article{he2025scaling,
  title={Scaling Cross-Embodiment World Models for Dexterous Manipulation},
  author={He, Zihao and Ai, Bo and Mu, Tongzhou and Liu, Yulin and Wan, Weikang and Fu, Jiawei and Du, Yilun and Christensen, Henrik I. and Su, Hao},
  journal={arXiv preprint arXiv:2511.01177},
  year={2025}
}</pre>
      </div>
    </section>

    <!-- Back to Home -->
    <div class="back-link">
      <a href="index.html">‚Üê Back to Home</a>
    </div>
  </div>

  <script>
    function copyCitation() {
      const bibtex = document.getElementById('bibtex').textContent;
      const button = document.querySelector('.copy-button');
      
      navigator.clipboard.writeText(bibtex).then(function() {
        button.textContent = 'Copied!';
        button.classList.add('copied');
        setTimeout(function() {
          button.textContent = 'Copy';
          button.classList.remove('copied');
        }, 2000);
      }).catch(function(err) {
        console.error('Failed to copy: ', err);
        // Fallback for older browsers
        const textArea = document.createElement('textarea');
        textArea.value = bibtex;
        document.body.appendChild(textArea);
        textArea.select();
        try {
          document.execCommand('copy');
          button.textContent = 'Copied!';
          button.classList.add('copied');
          setTimeout(function() {
            button.textContent = 'Copy';
            button.classList.remove('copied');
          }, 2000);
        } catch (err) {
          console.error('Fallback copy failed: ', err);
        }
        document.body.removeChild(textArea);
      });
    }
  </script>
</body>
</html>
